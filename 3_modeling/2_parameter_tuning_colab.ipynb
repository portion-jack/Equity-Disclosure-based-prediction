{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNPLfeeo5rDr",
        "outputId": "a9ee80b7-dc3b-4d6c-fc64-aeeed27da5e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.8 MB/s \n",
            "\u001b[?25hCollecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 75.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 56.2 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 56.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=440700df82f76dc78773137d047c6771127b73ad4e8402be2948f01d8afe58a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 stevedore-3.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr5AXXu_5dVs",
        "outputId": "ffe40c8b-0925-4cc1-f1d2-51d85dab415b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wve7pqoW5ZRV"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "import pandas as pd\n",
        "data=pd.read_csv('/content/drive/MyDrive/data/weighted_data.csv', encoding='cp949', index_col=0)\n",
        "target=pd.read_csv('/content/drive/MyDrive/data/y_data.csv', encoding='cp949', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C56b4Cvf5ZRY"
      },
      "outputs": [],
      "source": [
        "# import models\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "models_li = [RandomForestClassifier(), GradientBoostingClassifier(), ExtraTreesClassifier(), XGBClassifier()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EX8G4S2A5ZRZ"
      },
      "outputs": [],
      "source": [
        "# standard_scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "ssc = StandardScaler()\n",
        "data_ssc=ssc.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hTOqv7K5ZRa",
        "outputId": "51e9ec0c-1830-4f11-f4c5-0df9d6d73689"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'ccp_alpha': 0.0,\n",
              " 'class_weight': None,\n",
              " 'criterion': 'gini',\n",
              " 'max_depth': None,\n",
              " 'max_features': 'auto',\n",
              " 'max_leaf_nodes': None,\n",
              " 'max_samples': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 100,\n",
              " 'n_jobs': None,\n",
              " 'oob_score': False,\n",
              " 'random_state': None,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "RandomForestClassifier().get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-93taIKH5ZRa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score,KFold\n",
        "kfold = KFold(n_splits=3,random_state=42,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mdD8d5Iu9xCb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvBIK8yq5ZRb",
        "outputId": "721e3d3d-7bbf-4a55-8b1a-486fb9e24df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-18 04:26:49,739]\u001b[0m A new study created in memory with name: no-name-15b6c41b-6869-4409-9669-479738cbf255\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:27:08,587]\u001b[0m Trial 0 finished with value: 0.5115286748874536 and parameters: {'bootstrap': False, 'max_depth': 42, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 2000}. Best is trial 0 with value: 0.5115286748874536.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "3 fits failed out of a total of 3.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 254, in fit\n",
            "    % self.min_samples_split\n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "\u001b[33m[W 2022-11-18 04:27:10,571]\u001b[0m Trial 1 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:27:15,349]\u001b[0m Trial 2 finished with value: 0.5242904678019182 and parameters: {'bootstrap': False, 'max_depth': 67, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 800}. Best is trial 2 with value: 0.5242904678019182.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:27:22,465]\u001b[0m Trial 3 finished with value: 0.5243100411039343 and parameters: {'bootstrap': True, 'max_depth': 53, 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 1200}. Best is trial 3 with value: 0.5243100411039343.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:27:27,344]\u001b[0m Trial 4 finished with value: 0.5268349970640047 and parameters: {'bootstrap': True, 'max_depth': 32, 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 800}. Best is trial 4 with value: 0.5268349970640047.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:27:33,830]\u001b[0m Trial 5 finished with value: 0.5192014092777452 and parameters: {'bootstrap': False, 'max_depth': 69, 'min_samples_leaf': 2, 'min_samples_split': 9, 'n_estimators': 1000}. Best is trial 4 with value: 0.5268349970640047.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:27:41,344]\u001b[0m Trial 6 finished with value: 0.5319827754942259 and parameters: {'bootstrap': True, 'max_depth': 51, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 1200}. Best is trial 6 with value: 0.5319827754942259.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:27:52,586]\u001b[0m Trial 7 finished with value: 0.5191818359757291 and parameters: {'bootstrap': True, 'max_depth': 97, 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 1600}. Best is trial 6 with value: 0.5319827754942259.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:27:57,372]\u001b[0m Trial 8 finished with value: 0.5396163632804855 and parameters: {'bootstrap': True, 'max_depth': 11, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 800}. Best is trial 8 with value: 0.5396163632804855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:28:08,228]\u001b[0m Trial 9 finished with value: 0.514053630847524 and parameters: {'bootstrap': False, 'max_depth': 83, 'min_samples_leaf': 5, 'min_samples_split': 9, 'n_estimators': 1800}. Best is trial 8 with value: 0.5396163632804855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:28:16,790]\u001b[0m Trial 10 finished with value: 0.5166373067136426 and parameters: {'bootstrap': False, 'max_depth': 91, 'min_samples_leaf': 2, 'min_samples_split': 9, 'n_estimators': 1200}. Best is trial 8 with value: 0.5396163632804855.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "3 fits failed out of a total of 3.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 254, in fit\n",
            "    % self.min_samples_split\n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "\u001b[33m[W 2022-11-18 04:28:17,047]\u001b[0m Trial 11 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "3 fits failed out of a total of 3.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 254, in fit\n",
            "    % self.min_samples_split\n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "\u001b[33m[W 2022-11-18 04:28:17,309]\u001b[0m Trial 12 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "3 fits failed out of a total of 3.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 254, in fit\n",
            "    % self.min_samples_split\n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "\u001b[33m[W 2022-11-18 04:28:17,608]\u001b[0m Trial 13 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:28:19,510]\u001b[0m Trial 14 finished with value: 0.5192209825797612 and parameters: {'bootstrap': True, 'max_depth': 16, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}. Best is trial 8 with value: 0.5396163632804855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:28:23,025]\u001b[0m Trial 15 finished with value: 0.5345468780583285 and parameters: {'bootstrap': True, 'max_depth': 14, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}. Best is trial 8 with value: 0.5396163632804855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:28:24,303]\u001b[0m Trial 16 finished with value: 0.519123116069681 and parameters: {'bootstrap': True, 'max_depth': 14, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}. Best is trial 8 with value: 0.5396163632804855.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:28:28,025]\u001b[0m Trial 17 finished with value: 0.5294578195341554 and parameters: {'bootstrap': True, 'max_depth': 29, 'min_samples_leaf': 1, 'min_samples_split': 7, 'n_estimators': 600}. Best is trial 8 with value: 0.5396163632804855.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "3 fits failed out of a total of 3.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 254, in fit\n",
            "    % self.min_samples_split\n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "\u001b[33m[W 2022-11-18 04:28:28,518]\u001b[0m Trial 18 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "3 fits failed out of a total of 3.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
            "    for i, t in enumerate(trees)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in __call__\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
            "    for func, args, kwargs in self.items]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 254, in fit\n",
            "    % self.min_samples_split\n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "\u001b[33m[W 2022-11-18 04:28:28,983]\u001b[0m Trial 19 failed because of the following error: The value nan is not acceptable.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# RandomForestClassifier_parameter_tuning\n",
        "# based on optuna\n",
        "\n",
        "import optuna\n",
        "\n",
        "def rfc_object(trial):\n",
        "    prms={\n",
        "    'bootstrap': trial.suggest_categorical('bootstrap',[True, False]),\n",
        "    'max_depth': trial.suggest_int('max_depth',10,100),\n",
        "    'min_samples_leaf': trial.suggest_int('min_samples_leaf',1,5),\n",
        "    'min_samples_split': trial.suggest_int('min_samples_split',2,10),\n",
        "    'n_estimators': trial.suggest_int('n_estimators',200,2000,step=200)\n",
        "    }\n",
        "    model =RandomForestClassifier(**prms)\n",
        "    result = cross_val_score(\n",
        "        model,\n",
        "        data_ssc,\n",
        "        target['9일 뒤 종가'],\n",
        "        cv=kfold\n",
        "    )\n",
        "    return np.mean(result)\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(rfc_object,n_trials=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2YL7Yd-5ZRb",
        "outputId": "b999a9a2-407c-488a-bd1e-a1e1b79a828f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': 11,\n",
              " 'min_samples_leaf': 2,\n",
              " 'min_samples_split': 10,\n",
              " 'n_estimators': 800}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "rfc_best_prms=study.best_params\n",
        "rfc_best_prms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc=RandomForestClassifier(**rfc_best_prms)"
      ],
      "metadata": {
        "id": "hOvaz-nNBifs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc.get_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbQLqYFHBngq",
        "outputId": "70cec0b7-fa46-4ed0-af7b-05a61977526f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'ccp_alpha': 0.0,\n",
              " 'class_weight': None,\n",
              " 'criterion': 'gini',\n",
              " 'max_depth': 11,\n",
              " 'max_features': 'auto',\n",
              " 'max_leaf_nodes': None,\n",
              " 'max_samples': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_samples_leaf': 2,\n",
              " 'min_samples_split': 10,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 800,\n",
              " 'n_jobs': None,\n",
              " 'oob_score': False,\n",
              " 'random_state': None,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRioOWRu5ZRc",
        "outputId": "1d3e88b5-6cac-4c2e-f762-7b80e5417acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-18 04:29:53,198]\u001b[0m A new study created in memory with name: no-name-84f4f097-2230-4094-8567-77ede92818fe\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:29:59,817]\u001b[0m Trial 0 finished with value: 0.49352123703268735 and parameters: {'n_estimators': 1200, 'max_depth': 946, 'learning_rate': 0.993757058885463}. Best is trial 0 with value: 0.49352123703268735.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:30:13,776]\u001b[0m Trial 1 finished with value: 0.4706009003718927 and parameters: {'n_estimators': 1400, 'max_depth': 965, 'learning_rate': 0.17053235237873826}. Best is trial 0 with value: 0.49352123703268735.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:30:18,728]\u001b[0m Trial 2 finished with value: 0.5114503816793893 and parameters: {'n_estimators': 800, 'max_depth': 142, 'learning_rate': 0.6240491602066651}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:31:50,392]\u001b[0m Trial 3 finished with value: 0.4705226071638286 and parameters: {'n_estimators': 1000, 'max_depth': 41, 'learning_rate': 0.006782582830190724}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:31:59,628]\u001b[0m Trial 4 finished with value: 0.4807398708162067 and parameters: {'n_estimators': 1600, 'max_depth': 57, 'learning_rate': 0.6821419768510925}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:32:04,687]\u001b[0m Trial 5 finished with value: 0.48590722254844393 and parameters: {'n_estimators': 600, 'max_depth': 814, 'learning_rate': 0.772919700420379}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:32:16,415]\u001b[0m Trial 6 finished with value: 0.4782540614601683 and parameters: {'n_estimators': 1000, 'max_depth': 911, 'learning_rate': 0.14569301930050194}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:32:20,574]\u001b[0m Trial 7 finished with value: 0.4935799569387355 and parameters: {'n_estimators': 600, 'max_depth': 37, 'learning_rate': 0.6098345725520473}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:32:31,355]\u001b[0m Trial 8 finished with value: 0.48586807594441184 and parameters: {'n_estimators': 2000, 'max_depth': 81, 'learning_rate': 0.4412455308293059}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:32:35,885]\u001b[0m Trial 9 finished with value: 0.4526521824231748 and parameters: {'n_estimators': 800, 'max_depth': 25, 'learning_rate': 0.8597664022861501}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:32:39,002]\u001b[0m Trial 10 finished with value: 0.48336269328635745 and parameters: {'n_estimators': 200, 'max_depth': 345, 'learning_rate': 0.44768622185995344}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:32:42,318]\u001b[0m Trial 11 finished with value: 0.5012135447249951 and parameters: {'n_estimators': 400, 'max_depth': 301, 'learning_rate': 0.624320462123003}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:32:44,964]\u001b[0m Trial 12 finished with value: 0.4884517518105304 and parameters: {'n_estimators': 200, 'max_depth': 331, 'learning_rate': 0.5567333105360287}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:32:49,472]\u001b[0m Trial 13 finished with value: 0.4781953415541202 and parameters: {'n_estimators': 400, 'max_depth': 264, 'learning_rate': 0.35396410514567345}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:32:54,646]\u001b[0m Trial 14 finished with value: 0.49614405950283813 and parameters: {'n_estimators': 600, 'max_depth': 555, 'learning_rate': 0.7417999165125605}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:33:01,441]\u001b[0m Trial 15 finished with value: 0.4756508122920337 and parameters: {'n_estimators': 800, 'max_depth': 525, 'learning_rate': 0.3137006139471986}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:33:04,312]\u001b[0m Trial 16 finished with value: 0.4832844000782932 and parameters: {'n_estimators': 400, 'max_depth': 198, 'learning_rate': 0.8889137159932099}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:33:11,085]\u001b[0m Trial 17 finished with value: 0.49870816206694063 and parameters: {'n_estimators': 1200, 'max_depth': 685, 'learning_rate': 0.6235653334090414}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:33:16,369]\u001b[0m Trial 18 finished with value: 0.5037776472890977 and parameters: {'n_estimators': 800, 'max_depth': 416, 'learning_rate': 0.5161047863798218}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:33:25,074]\u001b[0m Trial 19 finished with value: 0.5038167938931297 and parameters: {'n_estimators': 1600, 'max_depth': 192, 'learning_rate': 0.5030297799610136}. Best is trial 2 with value: 0.5114503816793893.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# GradientBoostingClassifier_parameter_tuning\n",
        "# based on optuna\n",
        "\n",
        "import optuna\n",
        "\n",
        "def gbc_object(trial):\n",
        "    prms={\n",
        "    'n_estimators': trial.suggest_int('n_estimators',200,2000,step=200),\n",
        "    'max_depth': trial.suggest_int('max_depth',10,1000),\n",
        "    \"learning_rate\": trial.suggest_float(\"learning_rate\",1e-5,1),\n",
        "    }\n",
        "    model =GradientBoostingClassifier(**prms)\n",
        "    result = cross_val_score(\n",
        "        model,\n",
        "        data_ssc,\n",
        "        target['9일 뒤 종가'],\n",
        "        cv=kfold\n",
        "    )\n",
        "    return np.mean(result)\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(gbc_object,n_trials=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRMWmRJ45ZRd",
        "outputId": "5d145467-a2e9-43de-c1a0-49139c62a07b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 800, 'max_depth': 142, 'learning_rate': 0.6240491602066651}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "gbc_best_prms=study.best_params\n",
        "gbc_best_prms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gbc=GradientBoostingClassifier(**gbc_best_prms)\n",
        "gbc.get_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y8wcznKBu3u",
        "outputId": "6bc0fc3c-7154-43c2-9084-84f751a2ad0a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ccp_alpha': 0.0,\n",
              " 'criterion': 'friedman_mse',\n",
              " 'init': None,\n",
              " 'learning_rate': 0.6240491602066651,\n",
              " 'loss': 'deviance',\n",
              " 'max_depth': 142,\n",
              " 'max_features': None,\n",
              " 'max_leaf_nodes': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 800,\n",
              " 'n_iter_no_change': None,\n",
              " 'random_state': None,\n",
              " 'subsample': 1.0,\n",
              " 'tol': 0.0001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccb-MdvL5ZRd",
        "outputId": "4dc59644-0dd3-465f-8a85-44ef75292b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-18 04:33:35,979]\u001b[0m A new study created in memory with name: no-name-1eb1826d-3ff1-467c-bddc-8dedfe71d296\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:33:38,616]\u001b[0m Trial 0 finished with value: 0.49614405950283813 and parameters: {'n_estimators': 600, 'max_depth': 839}. Best is trial 0 with value: 0.49614405950283813.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:33:39,514]\u001b[0m Trial 1 finished with value: 0.5140732041495399 and parameters: {'n_estimators': 200, 'max_depth': 804}. Best is trial 1 with value: 0.5140732041495399.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:33:44,586]\u001b[0m Trial 2 finished with value: 0.5115286748874536 and parameters: {'n_estimators': 1000, 'max_depth': 298}. Best is trial 1 with value: 0.5140732041495399.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:33:48,392]\u001b[0m Trial 3 finished with value: 0.5038363671951459 and parameters: {'n_estimators': 600, 'max_depth': 895}. Best is trial 1 with value: 0.5140732041495399.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:33:49,299]\u001b[0m Trial 4 finished with value: 0.4935799569387355 and parameters: {'n_estimators': 200, 'max_depth': 562}. Best is trial 1 with value: 0.5140732041495399.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:33:51,884]\u001b[0m Trial 5 finished with value: 0.5038363671951459 and parameters: {'n_estimators': 600, 'max_depth': 20}. Best is trial 1 with value: 0.5140732041495399.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:33:59,823]\u001b[0m Trial 6 finished with value: 0.5089449990213349 and parameters: {'n_estimators': 1800, 'max_depth': 999}. Best is trial 1 with value: 0.5140732041495399.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:34:00,708]\u001b[0m Trial 7 finished with value: 0.5191818359757291 and parameters: {'n_estimators': 200, 'max_depth': 147}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:34:04,224]\u001b[0m Trial 8 finished with value: 0.5012526913290272 and parameters: {'n_estimators': 800, 'max_depth': 677}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:34:05,947]\u001b[0m Trial 9 finished with value: 0.508984145625367 and parameters: {'n_estimators': 400, 'max_depth': 223}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:34:13,868]\u001b[0m Trial 10 finished with value: 0.5115091015854375 and parameters: {'n_estimators': 1600, 'max_depth': 332}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:34:14,758]\u001b[0m Trial 11 finished with value: 0.491015854374633 and parameters: {'n_estimators': 200, 'max_depth': 24}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:34:19,953]\u001b[0m Trial 12 finished with value: 0.5165981601096105 and parameters: {'n_estimators': 1200, 'max_depth': 666}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:34:26,148]\u001b[0m Trial 13 finished with value: 0.4884321785085144 and parameters: {'n_estimators': 1400, 'max_depth': 507}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:34:31,450]\u001b[0m Trial 14 finished with value: 0.5089254257193189 and parameters: {'n_estimators': 1200, 'max_depth': 639}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:34:38,043]\u001b[0m Trial 15 finished with value: 0.5012722646310434 and parameters: {'n_estimators': 1200, 'max_depth': 373}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:34:47,367]\u001b[0m Trial 16 finished with value: 0.5114895282834214 and parameters: {'n_estimators': 2000, 'max_depth': 163}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:34:51,675]\u001b[0m Trial 17 finished with value: 0.5114699549814054 and parameters: {'n_estimators': 1000, 'max_depth': 679}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:34:57,759]\u001b[0m Trial 18 finished with value: 0.5064004697592485 and parameters: {'n_estimators': 1400, 'max_depth': 428}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:02,509]\u001b[0m Trial 19 finished with value: 0.5037776472890977 and parameters: {'n_estimators': 800, 'max_depth': 131}. Best is trial 7 with value: 0.5191818359757291.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# ExtraTreesClassifier_parameter_tuning\n",
        "# based on optuna\n",
        "\n",
        "import optuna\n",
        "\n",
        "def ettc_object(trial):\n",
        "    prms={\n",
        "    'n_estimators': trial.suggest_int('n_estimators',200,2000,step=200),\n",
        "    'max_depth': trial.suggest_int('max_depth',10,1000),\n",
        "    }\n",
        "    model =ExtraTreesClassifier(**prms)\n",
        "    result = cross_val_score(\n",
        "        model,\n",
        "        data_ssc,\n",
        "        target['9일 뒤 종가'],\n",
        "        cv=kfold\n",
        "    )\n",
        "    return np.mean(result)\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(ettc_object,n_trials=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQGsjWf15ZRe",
        "outputId": "8a371739-8469-4511-c5cd-9d2d37cbdc7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 200, 'max_depth': 147}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "ettc_best_prms=study.best_params\n",
        "ettc_best_prms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ettc=ExtraTreesClassifier(**ettc_best_prms)\n",
        "ettc.get_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HuUnf-aB845",
        "outputId": "4acea52c-024a-4968-e5f7-e6234671c5a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': False,\n",
              " 'ccp_alpha': 0.0,\n",
              " 'class_weight': None,\n",
              " 'criterion': 'gini',\n",
              " 'max_depth': 147,\n",
              " 'max_features': 'auto',\n",
              " 'max_leaf_nodes': None,\n",
              " 'max_samples': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 200,\n",
              " 'n_jobs': None,\n",
              " 'oob_score': False,\n",
              " 'random_state': None,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO3Wbrm25ZRe",
        "outputId": "fb367a0b-cf1c-4f02-b932-dd326a581945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-18 04:35:02,551]\u001b[0m A new study created in memory with name: no-name-665a63d9-d7b6-425e-b9c8-6da64a209875\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:04,157]\u001b[0m Trial 0 finished with value: 0.5089841456253671 and parameters: {'min_child_weight': 1, 'gamma': 1.1497952302996337, 'subsample': 0.9888344816118727, 'colsample_bytree': 0.3403096188239668, 'max_depth': 14}. Best is trial 0 with value: 0.5089841456253671.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:04,964]\u001b[0m Trial 1 finished with value: 0.5167155999217068 and parameters: {'min_child_weight': 2, 'gamma': 1.072629987718089, 'subsample': 0.7106236950055019, 'colsample_bytree': 0.32426229272321583, 'max_depth': 9}. Best is trial 1 with value: 0.5167155999217068.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:05,319]\u001b[0m Trial 2 finished with value: 0.4911528674887453 and parameters: {'min_child_weight': 9, 'gamma': 0.9211440567757445, 'subsample': 0.7603300547474644, 'colsample_bytree': 0.19104307825718805, 'max_depth': 13}. Best is trial 1 with value: 0.5167155999217068.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:06,124]\u001b[0m Trial 3 finished with value: 0.4782932080642004 and parameters: {'min_child_weight': 4, 'gamma': 4.97015743056738, 'subsample': 0.4732331899280058, 'colsample_bytree': 0.6053726367224664, 'max_depth': 17}. Best is trial 1 with value: 0.5167155999217068.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:07,457]\u001b[0m Trial 4 finished with value: 0.5243687610099824 and parameters: {'min_child_weight': 4, 'gamma': 2.582257177890854, 'subsample': 0.677278349384319, 'colsample_bytree': 0.8427013999850967, 'max_depth': 15}. Best is trial 4 with value: 0.5243687610099824.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:07,892]\u001b[0m Trial 5 finished with value: 0.509003718927383 and parameters: {'min_child_weight': 4, 'gamma': 3.5592907341101645, 'subsample': 0.17067267411400266, 'colsample_bytree': 0.9046590948904191, 'max_depth': 13}. Best is trial 4 with value: 0.5243687610099824.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:08,111]\u001b[0m Trial 6 finished with value: 0.480876883930319 and parameters: {'min_child_weight': 3, 'gamma': 3.7274469259848972, 'subsample': 0.1533575138308476, 'colsample_bytree': 0.2077247952454494, 'max_depth': 20}. Best is trial 4 with value: 0.5243687610099824.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:08,734]\u001b[0m Trial 7 finished with value: 0.5038559404971619 and parameters: {'min_child_weight': 2, 'gamma': 3.137706515257533, 'subsample': 0.33743783172684494, 'colsample_bytree': 0.46945352733172685, 'max_depth': 28}. Best is trial 4 with value: 0.5243687610099824.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:08,999]\u001b[0m Trial 8 finished with value: 0.4732628694460755 and parameters: {'min_child_weight': 8, 'gamma': 3.9666171121856757, 'subsample': 0.17585758559581388, 'colsample_bytree': 0.6536818320701179, 'max_depth': 7}. Best is trial 4 with value: 0.5243687610099824.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:09,501]\u001b[0m Trial 9 finished with value: 0.4911137208847132 and parameters: {'min_child_weight': 1, 'gamma': 4.41844043584637, 'subsample': 0.3635710590030262, 'colsample_bytree': 0.22824792710447195, 'max_depth': 9}. Best is trial 4 with value: 0.5243687610099824.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:10,833]\u001b[0m Trial 10 finished with value: 0.5242708944999022 and parameters: {'min_child_weight': 6, 'gamma': 2.1533971514933645, 'subsample': 0.7232578161766863, 'colsample_bytree': 0.9816223136623022, 'max_depth': 24}. Best is trial 4 with value: 0.5243687610099824.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:12,111]\u001b[0m Trial 11 finished with value: 0.5115482481894696 and parameters: {'min_child_weight': 6, 'gamma': 2.2226445242452004, 'subsample': 0.6899625746980267, 'colsample_bytree': 0.9490093007819949, 'max_depth': 24}. Best is trial 4 with value: 0.5243687610099824.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:13,397]\u001b[0m Trial 12 finished with value: 0.537110980622431 and parameters: {'min_child_weight': 6, 'gamma': 2.2255397730417315, 'subsample': 0.8946352517263307, 'colsample_bytree': 0.7923972225083097, 'max_depth': 22}. Best is trial 12 with value: 0.537110980622431.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:14,619]\u001b[0m Trial 13 finished with value: 0.5013701311411235 and parameters: {'min_child_weight': 7, 'gamma': 2.4769894795355283, 'subsample': 0.966581865486731, 'colsample_bytree': 0.7698493894367331, 'max_depth': 21}. Best is trial 12 with value: 0.537110980622431.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:15,903]\u001b[0m Trial 14 finished with value: 0.5038950871011939 and parameters: {'min_child_weight': 5, 'gamma': 1.7428581141485173, 'subsample': 0.8539200364849098, 'colsample_bytree': 0.7517716666273605, 'max_depth': 30}. Best is trial 12 with value: 0.537110980622431.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:16,995]\u001b[0m Trial 15 finished with value: 0.5064004697592485 and parameters: {'min_child_weight': 5, 'gamma': 2.9611203452364165, 'subsample': 0.5861352554446672, 'colsample_bytree': 0.8143677644946362, 'max_depth': 17}. Best is trial 12 with value: 0.537110980622431.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:17,845]\u001b[0m Trial 16 finished with value: 0.5243100411039342 and parameters: {'min_child_weight': 10, 'gamma': 1.7368809831527323, 'subsample': 0.8604670223311167, 'colsample_bytree': 0.6897658330510521, 'max_depth': 24}. Best is trial 12 with value: 0.537110980622431.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:18,446]\u001b[0m Trial 17 finished with value: 0.4911528674887453 and parameters: {'min_child_weight': 7, 'gamma': 1.6574322112587743, 'subsample': 0.5344116007838079, 'colsample_bytree': 0.4990404164487883, 'max_depth': 19}. Best is trial 12 with value: 0.537110980622431.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:19,798]\u001b[0m Trial 18 finished with value: 0.5576042278332355 and parameters: {'min_child_weight': 4, 'gamma': 0.5153854345979962, 'subsample': 0.8578483603632772, 'colsample_bytree': 0.8659792218360167, 'max_depth': 15}. Best is trial 18 with value: 0.5576042278332355.\u001b[0m\n",
            "\u001b[32m[I 2022-11-18 04:35:20,914]\u001b[0m Trial 19 finished with value: 0.5347034644744568 and parameters: {'min_child_weight': 7, 'gamma': 0.5391259818995473, 'subsample': 0.8833201591169364, 'colsample_bytree': 0.8530993968115111, 'max_depth': 22}. Best is trial 18 with value: 0.5576042278332355.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# XGBClassifier_parameter_tuning\n",
        "# based on optuna\n",
        "\n",
        "import optuna\n",
        "\n",
        "def xgbc_object(trial):\n",
        "    prms={\n",
        "    'min_child_weight': trial.suggest_int('min_child_weight',1,10),\n",
        "    'gamma': trial.suggest_float('gamma',0.5,5),\n",
        "    \"subsample\": trial.suggest_float(\"subsample\",1e-1,1),\n",
        "    'colsample_bytree': trial.suggest_float('colsample_bytree',1e-1,1),\n",
        "    'max_depth': trial.suggest_int('max_depth', 5, 30)\n",
        "    }\n",
        "    model =XGBClassifier(**prms)\n",
        "    result = cross_val_score(\n",
        "        model,\n",
        "        data_ssc,\n",
        "        target['9일 뒤 종가'],\n",
        "        cv=kfold\n",
        "    )\n",
        "    return np.mean(result)\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(xgbc_object,n_trials=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knnpMM4B5ZRe",
        "outputId": "468e74ba-36f6-4bc3-84d2-2a007e302039"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'min_child_weight': 4,\n",
              " 'gamma': 0.5153854345979962,\n",
              " 'subsample': 0.8578483603632772,\n",
              " 'colsample_bytree': 0.8659792218360167,\n",
              " 'max_depth': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "xgbc_best_prms=study.best_params\n",
        "xgbc_best_prms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgbc=XGBClassifier(**xgbc_best_prms)\n",
        "xgbc.get_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d84oTAq6djJ",
        "outputId": "3cbef675-08ee-4e34-9396-99ee22176931"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_score': 0.5,\n",
              " 'booster': 'gbtree',\n",
              " 'colsample_bylevel': 1,\n",
              " 'colsample_bynode': 1,\n",
              " 'colsample_bytree': 0.8659792218360167,\n",
              " 'gamma': 0.5153854345979962,\n",
              " 'learning_rate': 0.1,\n",
              " 'max_delta_step': 0,\n",
              " 'max_depth': 15,\n",
              " 'min_child_weight': 4,\n",
              " 'missing': None,\n",
              " 'n_estimators': 100,\n",
              " 'n_jobs': 1,\n",
              " 'nthread': None,\n",
              " 'objective': 'binary:logistic',\n",
              " 'random_state': 0,\n",
              " 'reg_alpha': 0,\n",
              " 'reg_lambda': 1,\n",
              " 'scale_pos_weight': 1,\n",
              " 'seed': None,\n",
              " 'silent': None,\n",
              " 'subsample': 0.8578483603632772,\n",
              " 'verbosity': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oBSE4QWGCPRa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 ('crawling')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "10621530bc52bc3dcaea48e2b7ef028942e35d2e6e9c9234a88fefd069caf90f"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}